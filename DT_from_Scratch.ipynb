{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DT_from_Scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s28mszcue56X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "X,y=load_iris(return_X_y=True,as_frame=True)\n",
        "\n",
        "df=pd.concat([X,y],axis=1)\n",
        "df=df.sample(frac=1,replace=False)"
      ],
      "metadata": {
        "id": "V_s8Q3Mfe-g5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx=df.iloc[:,:-1]#.values\n",
        "y=df.iloc[:,-1]#.values\n",
        "y.shape,xx.shape"
      ],
      "metadata": {
        "id": "UUBECm4Bfi5K"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining some global scope variables\n",
        "\n",
        "target_classes=list(sorted(y.unique()))\n",
        "x_columns=list(xx.columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "31KBsw_mpf_U"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First we need to formulate a splitting criterion \n",
        "In this case I will be using entropy_values\n",
        "\n",
        "used to determine how much information is saved by performing splitting\n",
        "LV divergence based understanding of how far is our probability distribution from the true optimal 1 probability score based distribution \n",
        "\n",
        "\n",
        "## Formula used is -summation of i over samples probi*log(prob_i)\n",
        "## Here samples are our classes and prob i is the number of instances in that class\n",
        "\n",
        "--> probi(log(Dist true)/log(probi))\n",
        "-----> Optimal value -probi*log(prob(i))\n",
        "\n",
        "\n",
        "we can even use gini index for splitting \n",
        "summation(pi*(1-pi)) #chossing a class *mistake made in choosing that class\n",
        "\n",
        "1-summmation(pi2)\n",
        "This is the measure of statistical dispersion amongsts classes\n",
        "We want this dispersion to be low \n",
        "\n"
      ],
      "metadata": {
        "id": "ELHK1ZNJgxuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_wts=y.map(\n",
        "    {0:1,1:3,2:1}\n",
        ")\n",
        "cls_wts.name='class_wts'\n",
        "type(cls_wts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cyKkElm6hHE",
        "outputId": "ac3a0f16-3c5d-42f1-c8b7-a8d9dcf824fb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def node_entropy_calculator(class_series,sample_wts=None):\n",
        "  '''\n",
        "  This array will only have values of the classes that is present in that node\n",
        "  If sample weights are present then we will have to group by class and find sum of sample_weights and then perform the further computation\n",
        "\n",
        "  sample_wts is itself a series\n",
        "\n",
        "  parameter --> Series\n",
        "  return entropy value\n",
        "\n",
        "  [0,1,1,2,0]\n",
        "  pi*logpi for each of three instances\n",
        "\n",
        "  '''\n",
        "  global target_classes\n",
        "\n",
        "  temp_num=class_series.value_counts().reindex(target_classes)#Series\n",
        "\n",
        "  if isinstance(sample_wts,type(pd.Series([1]))):\n",
        "    temp_df=pd.concat([class_series,sample_wts],axis=1)\n",
        "    temp_num=temp_df.groupby(class_series.name)[sample_wts.name].sum()\n",
        "    temp_num=temp_num.reindex(target_classes)\n",
        "  \n",
        "  temp_num=temp_num[temp_num>0]\n",
        "\n",
        "  if len(temp_num)==0:\n",
        "    return 0\n",
        "\n",
        "  prob_class= temp_num/temp_num.sum()\n",
        "  log_prob_class=np.log(prob_class)\n",
        "\n",
        "  entropy=-1*((prob_class*log_prob_class).sum())\n",
        "\n",
        "  return entropy\n",
        "\n",
        "\n",
        "\n",
        "def splitter(col_series,split_vaue):\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "# node_entropy_calculator(y)#This is the parent node 0 entropy which we intend to reduce\n",
        "# node_entropy_calculator(y,cls_wts)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bstrc7opeyO",
        "outputId": "6c017025-7cc2-42e8-df8a-4080d437c1fd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    True\n",
              "1    True\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def overall_entropy_calculator(col,split_value,target,sample_wts=None,verbose=0):\n",
        "  '''\n",
        "  Will compute and return just the entropy for the classes generated using the provided splitter\n",
        "  Params--> Column (series), splitting_value val ,target (series)\n",
        "  return--> Entropy score\n",
        "  '''\n",
        "  if isinstance(sample_wts,type(pd.Series([1]))):\n",
        "    df=pd.concat([col,target,sample_wts],axis=1)\n",
        "    wt_name=sample_wts.name\n",
        "  else:\n",
        "    df=pd.concat([col,target],axis=1)\n",
        "  \n",
        "  col_name=col.name\n",
        "  target_name=target.name\n",
        "  \n",
        "\n",
        "  if isinstance(split_value,str):\n",
        "    lt=df[df[col_name]!=split_value]\n",
        "    rt=df[df[col_name]==split_value]\n",
        "  else:\n",
        "    lt=df[df[col_name]<=split_value]\n",
        "    rt=df[df[col_name]>split_value]\n",
        "\n",
        "  if verbose:\n",
        "    display(rt)\n",
        "    display(lt)\n",
        "\n",
        "  if isinstance(sample_wts,type(pd.Series([1]))):\n",
        "    lt_entropy=node_entropy_calculator(lt[target_name],lt[wt_name])\n",
        "    rt_entropy=node_entropy_calculator(rt[target_name],rt[wt_name])\n",
        "  else:\n",
        "    lt_entropy=node_entropy_calculator(lt[target_name])\n",
        "    rt_entropy=node_entropy_calculator(rt[target_name])\n",
        "\n",
        "  n_left=lt.shape[0]\n",
        "  n_right=rt.shape[0]\n",
        "  n_total=df.shape[0]\n",
        "\n",
        "  #Weighted entropy score needs to be computed\n",
        "  wt_entropy=(n_left/n_total)*(lt_entropy) + (n_right/n_total)*(rt_entropy)\n",
        "  return wt_entropy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "overall_entropy_calculator(xx.iloc[:,0],xx.iloc[:,0].unique()[0],y,\n",
        "                           sample_wts=cls_wts)\n",
        "\n",
        "\n",
        "overall_entropy_calculator(xx.iloc[:,0],xx.iloc[:,0].unique()[0],y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wbY2fSdfmL0",
        "outputId": "2fcd547d-71a1-4297-c7e1-2aab671f4f9b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9432529919645607"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We will create splits for all possible combinations of column and unique column values\n",
        "\n",
        "\n",
        "Fn 1-->Check for best split value withing each column\n",
        "and finally output the placeholder dictionary with \n",
        "\n",
        "Fn 2-->Compare entropy values of each column #Comparer that takes dictionary and sorting argument and returns the key of minimum splitter\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_QmJIfRS8vE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# entropy_placeholder={}\n",
        "\n",
        "def detremine_splitter(xx,y):\n",
        "\n",
        "  for col in xx.columns:\n",
        "    entropy=np.inf#need to reduce\n",
        "    for splitter in xx[col].unique():\n",
        "      temp_entropy=overall_entropy_calculator(\n",
        "          col=xx[col],split_value=splitter,target=y\n",
        "      )\n",
        "      if temp_entropy<entropy:\n",
        "        entropy=temp_entropy\n",
        "        col_splitter=(col,splitter,entropy)\n",
        "        # print(f'splitter updated to {nm}')\n",
        "\n",
        "  return col_splitter\n",
        "# detremine_splitter(xx,y)"
      ],
      "metadata": {
        "id": "GsYyondef71l"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[:50].value_counts()#.argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkxijDGDJ7Wk",
        "outputId": "36b9bac2-03df-4b1c-b0d4-c16dfa8811bb"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    19\n",
              "2    17\n",
              "1    14\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_leaf_node(y):\n",
        "  return y.value_counts().argmin()"
      ],
      "metadata": {
        "id": "ZjSwTAfi_x5n"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to find the splitter and then split the dataset into right and left datasets and perform the splitting on the created datasets \n",
        "\n",
        "\n",
        "We can add if and procedural loop as the recuerssion is at the end \n",
        "And we have tail recurssion"
      ],
      "metadata": {
        "id": "kzxjhVzwEj1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class node:\n",
        "  def __init__(self,val):\n",
        "    self.val=val\n",
        "    self.left=None\n",
        "    self.right=None\n",
        "\n",
        "dt=node(-1)\n",
        "\n",
        "\n",
        "\n",
        "# idx"
      ],
      "metadata": {
        "id": "6xSLu2QUKl7v"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def d_tree(xx,y,max_depth,dt,direction=''):\n",
        "  if xx.shape[0]==0:\n",
        "    return\n",
        "  if max_depth==0:\n",
        "    print(calculate_leaf_node(y))\n",
        "    dt.val=('leaf',calculate_leaf_node(y))\n",
        "    return \n",
        "  \n",
        "  col,split,_=detremine_splitter(xx,y)\n",
        "  dt.val=(col,split,direction,_)\n",
        "  print(dt.val)\n",
        "  dt.left=node(-1)\n",
        "  dt.right=node(-1)\n",
        "\n",
        "\n",
        "  idx_rt=xx[xx[col]>split].index\n",
        "  idx_lt=xx[xx[col]<=split].index\n",
        "\n",
        "  xx_rt=xx.loc[idx_rt]\n",
        "  xx_lt=xx.loc[idx_lt]\n",
        "\n",
        "  y_rt=y.loc[idx_rt]\n",
        "  y_lt=y.loc[idx_lt]\n",
        "\n",
        "  d_tree(xx_lt,y_lt,max_depth-1,dt.left,direction='<=')\n",
        "  d_tree(xx_rt,y_rt,max_depth-1,dt.right,direction='>')\n",
        "\n",
        "\n",
        "\n",
        "d_tree(xx,y,2,dt=dt)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqy_Mvlh_55s",
        "outputId": "65f2f1bc-7bb6-46a1-8c43-bb2517b5e402"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('petal width (cm)', 0.6, '', 0.46209812037329684)\n",
            "('petal width (cm)', 0.2, '<=', -0.0)\n",
            "0\n",
            "0\n",
            "('petal width (cm)', 1.7, '>', 0.2147644654371359)\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt.left.val,dt.val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c9IiQKkNSDn",
        "outputId": "8bc432f3-bc8f-40fc-c9a4-33bbea1918b1"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('petal width (cm)', 0.2, '<=', -0.0),\n",
              " ('petal width (cm)', 0.6, '', 0.46209812037329684))"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def BFS(root):\n",
        "  placeholder=[]\n",
        "  placeholder.append(root)\n",
        "\n",
        "  while len(placeholder)>0:\n",
        "    temp_root=placeholder.pop(0)\n",
        "    print(temp_root.val)\n",
        "\n",
        "    if temp_root.left:\n",
        "      placeholder.append(temp_root.left)\n",
        "    if temp_root.right:\n",
        "      placeholder.append(temp_root.right)\n",
        "    \n",
        "BFS(dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwhdf9qoOPza",
        "outputId": "aafe0b9a-dede-4857-beb8-08730a9d6353"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('petal width (cm)', 0.6, '', 0.46209812037329684)\n",
            "('petal width (cm)', 0.2, '<=', -0.0)\n",
            "('petal width (cm)', 1.7, '>', 0.2147644654371359)\n",
            "('leaf', 0)\n",
            "('leaf', 0)\n",
            "('leaf', 1)\n",
            "('leaf', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAdqy_SWR76Z",
        "outputId": "07aaba0c-9d47-4207-e9f6-b09f023214c7"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHZoWljmR-tQ",
        "outputId": "c6a1b682-a46c-4204-dfcf-6e93421c34e9"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xV9FdWEFSAc4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}